{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">First, we import the necessary libraries.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import features\n",
    "#!pip install --user imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import image_generator\n",
    "import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/val/images\\ILSVRC2012_val_00018549.JPEG pencil box, pencil case\n",
      "images/val/images\\ILSVRC2012_val_00042874.JPEG scuba diver\n",
      "images/val/images\\ILSVRC2012_val_00024143.JPEG pot, flowerpot\n",
      "images/val/images\\ILSVRC2012_val_00026369.JPEG space bar\n",
      "images/val/images\\ILSVRC2012_val_00012663.JPEG Petri dish\n",
      "images/val/images\\ILSVRC2012_val_00021419.JPEG tobacco shop, tobacconist shop, tobacconist\n",
      "images/val/images\\ILSVRC2012_val_00042860.JPEG Saint Bernard, St Bernard\n",
      "images/val/images\\ILSVRC2012_val_00011560.JPEG viaduct\n",
      "images/val/images\\ILSVRC2012_val_00040447.JPEG water snake\n",
      "images/val/images\\ILSVRC2012_val_00018870.JPEG jackfruit, jak, jack\n"
     ]
    }
   ],
   "source": [
    "image_generator.main()\n",
    "imgGen = image_generator.ImageGenerator('images/val/images', 'images/val/val.txt', 'images/val/synset_words.txt')\n",
    "label_list = imgGen.get_label_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Running the premodel**</font>\n",
    "<br /><br />\n",
    "<font size=\"3\">We train the premodel with 18k images and receive labels for the 2k test images.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percentage = features.prototype(20000, (['lg', 'lg', 'lg'], ['lg', 'lg', 'lg']))          # using logistic regression for the premodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Testing the accuracy of the premodel**</font>\n",
    "<br /><br />\n",
    "<font size=\"3\">First, we extract the predicted models for the 2k images.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_num_from_name(img_name):          # obtaining the image number from image name\n",
    "    ext = []\n",
    "    for i in range(len(img_name)):\n",
    "        if i > 14 and i < 23:\n",
    "            ext.append(img_name[i])\n",
    "    j = 0\n",
    "    for i in range(len(ext)):\n",
    "        if ext[i] == '0':\n",
    "            j = j + 1\n",
    "        if ext[i] != '0':\n",
    "            break\n",
    "    rightNum = []\n",
    "    for i in range(j, len(ext)):\n",
    "        rightNum.append(ext[i])\n",
    "    rightNum = ''.join(rightNum)\n",
    "    rightNum = int(rightNum)\n",
    "    return rightNum\n",
    "\n",
    "\n",
    "predicted_models = []\n",
    "for i in range(len(percentage[4][0])):\n",
    "    img_paths = (percentage[4][0][i][0])\n",
    "    img_nums = (img_num_from_name(img_paths))\n",
    "    if percentage[4][0][i][4] == 'tf-mobilenet_v1' and percentage[4][0][i][3] == 1:\n",
    "        predicted_models.append([img_nums, 'mobilenet_v1'])\n",
    "    elif percentage[4][0][i][4] == 'tf-inception_v4' and percentage[4][0][i][3] == 2:\n",
    "        predicted_models.append([img_nums, 'inception_v4'])\n",
    "    elif percentage[4][0][i][4] == 'tf-resnet_v1_152' and percentage[4][0][i][3] == 3:\n",
    "        predicted_models.append([img_nums, 'resnet_v1_152'])\n",
    "    elif percentage[4][0][i][4] == 'failed':\n",
    "        predicted_models.append([img_nums, 'failed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Now, we obtain the accuracy results from the database.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premodel accuracy = 0.742\n"
     ]
    }
   ],
   "source": [
    "accuracy_premodel = 0\n",
    "for i in range(len(predicted_models)):\n",
    "    if predicted_models[i][1] != 'failed':\n",
    "        accuracy_premodel = accuracy_premodel + (database.get_model_top_1(\"inference\", predicted_models[i][0], predicted_models[i][1]))\n",
    "print(\"Premodel accuracy = {}\".format(accuracy_premodel/len(predicted_models)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Comparing the results to MobileNet, Inception and ResNet**</font>\n",
    "<br /><br />\n",
    "<font size=\"3\">We start by getting the image numbers of the 2k test images.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_nums = []\n",
    "img_paths = []\n",
    "for i in range(len(percentage[4][0])):\n",
    "    img_paths.append(percentage[4][0][i][0])\n",
    "img_nums = []\n",
    "for i in range(len(img_paths)):\n",
    "    img_nums.append(img_num_from_name(img_paths[i]))\n",
    "\n",
    "len(img_nums) == len(set(img_nums))           # making sure there are no duplicates\n",
    "\n",
    "#results = []\n",
    "#img_path_list = []\n",
    "#img_labels = []\n",
    "#for i in range(len(img_nums)):\n",
    "    #img_path, img_label = imgGen.get_image_data(img_nums[i])\n",
    "    #img_path_list.append(img_path)\n",
    "    #img_labels.append(img_label)\n",
    "#print(len(img_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Finally, we obtain the accuracy results from the database.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobilenet top 1 accuracy = 0.7105\n",
      "Inception top 1 accuracy = 0.7995\n",
      "ResNet top 1 accuracy = 0.762\n"
     ]
    }
   ],
   "source": [
    "mobilenet_right = 0\n",
    "for i in range(len(img_nums)):\n",
    "    mobilenet_right = mobilenet_right + (database.get_model_top_1(\"inference\", img_nums[i], 'mobilenet_v1'))\n",
    "print(\"Mobilenet top 1 accuracy = {}\".format(mobilenet_right/len(img_nums)))\n",
    "\n",
    "inception_right = 0\n",
    "for i in range(len(img_nums)):\n",
    "    inception_right = inception_right + (database.get_model_top_1(\"inference\", img_nums[i], 'inception_v4'))\n",
    "print(\"Inception top 1 accuracy = {}\".format(inception_right/len(img_nums)))\n",
    "\n",
    "resnet_right = 0\n",
    "for i in range(len(img_nums)):\n",
    "    resnet_right = resnet_right + (database.get_model_top_1(\"inference\", img_nums[i], 'resnet_v1_152'))\n",
    "print(\"ResNet top 1 accuracy = {}\".format(resnet_right/len(img_nums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
